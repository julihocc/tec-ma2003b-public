\documentclass[aspectratio=169]{beamer}

% Presentation metadata
\title{Factor Analysis}
\author{Dr. Juliho Castillo}
\institute{Tecnológico de Monterrey}
\date{\today}

% Additional packages for the presentation
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish]{babel}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{listings}
\usepackage{xcolor}

% Use Metropolis theme with a blue color palette
% (Metropolis should be available in the TeX distribution; if not, install the MTheme package.)
\usetheme{metropolis}
% Metro options: tidy title and a subtle progress indicator
\metroset{titleformat=smallcaps,progressbar=frametitle}


\begin{document}

% Title slide
\begin{frame}
    \titlepage
\end{frame}

% Table of contents
\begin{frame}
    \tableofcontents
\end{frame}

% Section: Introducción

\section{Introduction}

\begin{frame}[fragile]
    \frametitle{What is Factor Analysis?}
    \begin{itemize}
        \item A statistical method for modeling relationships among \textbf{observed variables}. \pause
        \item It uses a smaller number of \textit{unobserved variables}, known as \textbf{factors}. \pause
        \item Often used in an \textit{unsupervised manner} to discover underlying patterns.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts}
    \begin{itemize}
        \item \textbf{Factors (or Latent Variables):} \pause
              \begin{itemize}
                  \item These are the underlying, unobserved variables. \pause
                  \item Example: A latent variable like "fairness" might be composed of observed variables like "demeanor" and "preparation for trial."
              \end{itemize}
        \item \textbf{The Core Assumption:} \pause
              \begin{itemize}
                  \item Observed variables are a linear combination of a few common factors and a unique factor for each variable.
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Factor Analysis vs. Principal Component Analysis (PCA)}
    \begin{itemize}
        \item \textbf{PCA:} Primarily a \textit{dimensionality reduction} technique. It focuses on summarizing the data by finding the directions of maximum variance. \pause
        \item \textbf{Factor Analysis:} Aims to explain the \textit{latent structure} of the data and identify the underlying constructs that explain the observed correlations. \pause
        \item \textbf{Summary:} While both reduce the number of variables, they have different goals.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{A Word of Caution}
    \begin{itemize}
        \item Factor analysis is a \textit{modeling technique}. \pause
        \item A confirmatory factor analysis cannot \textit{prove} a model is correct, only that it is plausible. \pause
        \item The method can be ``fragile'' because multiple, equally valid models might exist for the same dataset.
    \end{itemize}
\end{frame}

\section{Principal Component Analysis}

\begin{frame}
    \frametitle{Refresher: What is PCA?}
    \begin{itemize}
        \item Principal Component Analysis (PCA) is a linear method for \textbf{dimension reduction}. \pause
        \item It finds orthogonal directions (principal components) that capture the largest possible variance in the data. \pause
        \item PCA produces new variables (components) that are linear combinations of the original observed variables. \pause
        \item Use cases: visualization, noise reduction, pre-processing before supervised learning, and exploratory data analysis. \pause
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Mathematical formulation}
    Let $\mathbf{x}\in\mathbb{R}^p$ be a random vector with mean $\mu$ and covariance matrix $\Sigma$. After centering the data ($\mathbf{x}-\mu$):
    \begin{itemize}
        \item Find eigenvalues $\lambda_1\ge\lambda_2\ge\cdots\ge\lambda_p$ and orthonormal eigenvectors $\mathbf{v}_1,\dots,\mathbf{v}_p$ of $\Sigma$: $\Sigma\mathbf{v}_j=\lambda_j\mathbf{v}_j$. \pause
        \item The $j$-th principal component is $z_j=\mathbf{v}_j^{\top}(\mathbf{x}-\mu)$. \pause
        \item Variance explained by component $j$ is $\mathrm{Var}(z_j)=\lambda_j$. The proportion explained is $\lambda_j/\sum_{k=1}^p\lambda_k$. \pause
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Computation steps (practical)}
    \begin{enumerate}
        \item Standardize variables if they are on different scales (use correlation matrix) or center only if scales are comparable (use covariance matrix). \pause
        \item Compute covariance (or correlation) matrix $S$ from the data. \pause
        \item Compute eigen decomposition $S=V\Lambda V^{\top}$. \pause
        \item Form principal component scores: $Z = X_c V$ (where $X_c$ is centered data and columns of $V$ are eigenvectors). \pause
        \item Inspect eigenvalues, cumulative variance, and scree plot to decide how many components to keep. \pause
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Deciding how many components to retain}
    Common heuristics and formal approaches:
    \begin{itemize}
        \item Kaiser criterion: keep components with eigenvalue $>1$ (applies when using correlation matrix). \pause
        \item Cumulative variance: keep the smallest number of components that explain a target (e.g., 70--90\%) of total variance. \pause
        \item Scree plot: look for the "elbow" where additional components contribute little incremental variance. \pause
        \item Parallel analysis: compare empirical eigenvalues to those obtained from random data — keep components with larger eigenvalues than random. \pause
    \end{itemize}
\end{frame}

% Quick code example overview (refer to external script instead of showing full code)
\begin{frame}
    \frametitle{PCA: quick code example — overview}
    \begin{itemize}
        \item Script location: \texttt{lessons/4\_Factor\_Analysis/code/pca\_example/pca\_example.py}. \pause
        \item Main steps performed by the script: \pause
              \begin{itemize}
                  \item Generate a small synthetic dataset with two latent factors and noise. \pause
                  \item Standardize variables (so the correlation matrix behavior is used). \pause
                  \item Fit PCA, extract eigenvalues and explained-variance ratios. \pause
                  \item Print eigenvalues, explained ratio and cumulative explained variance; save a scree plot to \texttt{lessons/4\_Factor\_Analysis/code/pca\_example/pca\_scree.png}. \pause
              \end{itemize}
        \item How to run (recommended): \texttt{cd lessons/4\_Factor\_Analysis/code/pca\_example \&\& python pca\_example.py} — run this before compiling the slides if you want to embed the generated image. \pause
        \item Why we keep code separate: cleaner slides, easier to test and version examples, and learners can run the script locally to reproduce results.\pause
    \end{itemize}
    \vspace{6pt}
    % Optional: if you prefer the scree plot inside the slides, run the example first and then add an \includegraphics command here.
\end{frame}

\begin{frame}
    \frametitle{PCA vs Factor Analysis (reminder)}
    \begin{itemize}
        \item PCA: descriptive linear combinations that maximize variance; components are exact linear functions of observed variables and need not have a causal or measurement model interpretation. \pause
        \item Factor Analysis: a statistical model that explicitly decomposes observed variance into common (shared) variance explained by latent factors and unique variance (errors). \pause
        \item Practical rule: use PCA for dimension reduction and data compression; use Factor Analysis when your goal is to model latent constructs and separate common from unique variance. \pause
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Practical tips and pitfalls}
    \begin{itemize}
        \item Always check variable scales; standardize when necessary. \pause
        \item PCA is sensitive to outliers — inspect data and consider robust alternatives if needed. \pause
        \item Interpret components via loadings (eigenvectors) and by examining which variables contribute strongly to each component. \pause
        \item Rotation is not standard in PCA (rotation reassigns variance) — if interpretability is a priority, consider Factor Analysis with rotation. \pause
        \item When reporting, include: eigenvalues table, proportion of variance, cumulative variance, scree plot, and a table of loadings (component matrix). \pause
    \end{itemize}
\end{frame}

\section{Investment allocation example}

\begin{frame}
    \frametitle{European Stock Markets: PCA Analysis}
    This section demonstrates PCA applied to financial markets using synthetic European stock market data.
    \begin{itemize}
        \item \textbf{Dataset}: 4 major European indices (DAX, SMI, CAC, FTSE) over 1,860 trading days. \pause
        \item \textbf{Research Question}: How integrated are European financial markets? Can we identify common market factors? \pause
        \item \textbf{Method}: Standardized PCA on correlation matrix of daily returns. \pause
    \end{itemize}
    \vspace{6pt}
    Script: \texttt{lessons/4\_Factor\_Analysis/code/invest\_example/invest\_example.py}
\end{frame}

\begin{frame}
    \frametitle{Dataset: European Market Indices}
    \begin{itemize}
        \item \textbf{DAX (Germany)}: Frankfurt Stock Exchange — largest European economy \pause
        \item \textbf{SMI (Switzerland)}: Swiss Market Index — major financial center \pause
        \item \textbf{CAC (France)}: Paris Stock Exchange — core eurozone market \pause
        \item \textbf{FTSE (UK)}: London Stock Exchange — major international hub \pause
    \end{itemize}
    \vspace{12pt}
    \textbf{Financial Context:}
    \begin{itemize}
        \item Daily returns standardized (mean=0, std=1) for scale-invariant analysis \pause
        \item Captures correlation structure across different currencies and economies \pause
        \item Reflects market integration through EU membership and globalization \pause
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Typical PCA Results: Market Integration}
    When running the analysis, we observe:
    \begin{itemize}
        \item \textbf{PC1}: Explains $\sim$97\% of total variance \pause
              \begin{itemize}
                  \item Eigenvalue $\approx$ 3.9 (well above Kaiser threshold of 1.0) \pause
                  \item Represents a \textit{common European market factor} \pause
                  \item All markets load positively — they move together \pause
              \end{itemize}
        \item \textbf{PC2-PC4}: Explain only $\sim$3\% combined variance \pause
              \begin{itemize}
                  \item Capture market-specific idiosyncrasies \pause
                  \item Currency effects, country-specific political events \pause
                  \item Largely noise for portfolio construction \pause
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Financial Interpretation: Market Factor}
    \textbf{PC1 as a Market Factor:}
    \begin{itemize}
        \item Captures \textit{systematic risk} — movements common to all markets \pause
        \item Driven by: EU-wide economic conditions, global financial sentiment, major central bank policies \pause
        \item High loadings on all indices $\rightarrow$ European markets are highly integrated \pause
    \end{itemize}
    \vspace{12pt}
    \textbf{Implications for Portfolio Management:}
    \begin{itemize}
        \item \textit{Limited diversification benefit} from spreading across European markets alone \pause
        \item Most portfolio variance comes from exposure to the common factor \pause
        \item Geographic diversification requires markets with different factor exposures \pause
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Visualization: Scree Plot Analysis}
    The scree plot shows a dramatic \textit{``cliff''} pattern:
    \begin{itemize}
        \item Sharp drop from PC1 ($\lambda \approx 3.9$) to PC2 ($\lambda \approx 0.09$) \pause
        \item Clear ``elbow'' indicates one dominant factor \pause
        \item Remaining components are essentially flat (noise floor) \pause
    \end{itemize}
    \vspace{12pt}
    \textbf{Decision Rule:}
    \begin{itemize}
        \item Kaiser criterion: Retain PC1 only ($\lambda > 1$) \pause
        \item Variance threshold: PC1 alone exceeds any reasonable cutoff (80\%, 90\%, 95\%) \pause
        \item Practical conclusion: European markets can be summarized by a single factor \pause
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Biplot: Markets and Time Periods}
    The biplot reveals the factor structure:
    \begin{itemize}
        \item \textbf{Variable arrows} (red): Show market loadings on PC1-PC2 \pause
              \begin{itemize}
                  \item All arrows point in similar direction $\rightarrow$ positive correlation \pause
                  \item Arrow length reflects contribution to variance \pause
                  \item Angle between arrows shows correlation strength \pause
              \end{itemize}
        \item \textbf{Observation points}: Individual trading days in PC space \pause
              \begin{itemize}
                  \item Horizontal spread (PC1): Common market movements \pause
                  \item Vertical spread (PC2): Minor market-specific deviations \pause
                  \item Outliers may represent crisis periods or major events \pause
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Practical Applications}
    \textbf{Risk Management:}
    \begin{itemize}
        \item Use PC1 scores as a single \textit{European market risk factor} \pause
        \item Portfolio $\beta$ to PC1 determines systematic risk exposure \pause
        \item Stress testing: model extreme PC1 movements \pause
    \end{itemize}
    \vspace{6pt}
    \textbf{Portfolio Construction:}
    \begin{itemize}
        \item Market-neutral strategies require offsetting PC1 exposure \pause
        \item Alpha generation focuses on PC2-PC4 (idiosyncratic components) \pause
        \item Diversification requires assets uncorrelated with European factor \pause
    \end{itemize}
    \vspace{6pt}
    \textbf{Performance Attribution:}
    \begin{itemize}
        \item Decompose returns into market factor (PC1) + specific factors (PC2+) \pause
        \item Distinguish skill from market timing \pause
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Code Example: Running the Analysis}
    \begin{itemize}
        \item \textbf{Data preparation}: \texttt{fetch\_invest.py} generates synthetic European market data \pause
        \item \textbf{Main analysis}: \texttt{invest\_example.py} performs PCA with detailed financial interpretation \pause
        \item \textbf{Outputs}: 
              \begin{itemize}
                  \item Eigenvalues, explained variance ratios, cumulative variance \pause
                  \item \texttt{invest\_scree.png}: Scree plot for component selection \pause
                  \item \texttt{invest\_biplot.png}: Biplot of markets and time periods \pause
              \end{itemize}
        \item \textbf{Usage}: \texttt{cd code/invest\_example \&\& python invest\_example.py} \pause
    \end{itemize}
    \vspace{6pt}
    The script includes detailed py-percent comments for interactive exploration and financial interpretation of all results.
\end{frame}



\end{document}
