\documentclass{beamer}

\usetheme{Madrid} % A clean and professional theme

\title{Factor Methods in Multivariate Statistics}
\author{Based on Daniel Zelterman's \\ \textit{Applied Multivariate Statistics with R}}
\date{\today}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx} % Required for including images

% Custom commands for consistent styling
\newcommand{\R}{\texttt{R}}
\newcommand{\code}[1]{\texttt{#1}}

\begin{document}

\frame{\titlepage}

\begin{frame}
    \frametitle{Outline}
    \tableofcontents
\end{frame}

\section{Introduction to Factor Methods}

\begin{frame}
    \frametitle{What are Factor Methods?}
    \begin{itemize}
        \item Deal with data where multiple variables are collected.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Why use Factor Methods?}
    \begin{itemize}
        \item Goal: \alert{Data reduction} or \alert{structural simplification}.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Latent Structures}
    \begin{itemize}
        \item Identify underlying (latent) structures within complex multivariate datasets.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{When to apply them}
    \begin{itemize}
        \item Useful when variables are highly correlated, suggesting they measure common unobserved concepts.
    \end{itemize}
\end{frame}

\section{Principal Component Analysis (PCA)}

\begin{frame}
    \frametitle{PCA: Concept}
    \begin{itemize}
        \item A technique to transform a large set of correlated variables into a smaller set of uncorrelated variables called \alert{principal components}.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Components}
    \begin{itemize}
        \item Each principal component is a linear combination of the original variables.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Variance}
    \begin{itemize}
        \item The first principal component accounts for the largest possible variance in the data.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Orthogonality}
    \begin{itemize}
        \item Subsequent components account for decreasing amounts of variance and are \alert{orthogonal} to the preceding components.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Goal}
    \begin{itemize}
        \item Goal: To capture as much variance as possible with as few components as possible, thereby reducing dimensionality.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Mathematical Basis}
    \begin{itemize}
        \item Involves finding the \alert{eigenvalues} and \alert{eigenvectors} of the covariance (or correlation) matrix $\mathbf{S}$ of the data.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Eigen-quantities}
    \begin{itemize}
        \item Eigenvalues ($\lambda_i$) represent the variance explained by each principal component.
        \item Eigenvectors define the directions (loadings) of the principal components in the original variable space.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Loadings}
    \begin{itemize}
        \item Loadings: Coefficients $w_{ij}$ indicating the contribution of each original variable to a principal component. Largest absolute loadings are most important for interpretation.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Variance Explained}
    \begin{itemize}
        \item The proportion of total variance accounted for by each component (eigenvalue / sum of all eigenvalues).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Scree Plot}
    \begin{itemize}
        \item Plots ordered eigenvalues ($\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_p$) to visually assess the number of important components. Look for an "elbow" in the plot.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Biplot}
    \begin{itemize}
        \item Displays both observations and variable loadings in a low-dimensional space (usually the first two principal components). Arrows indicate variable directions; points represent observations.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{R: PCA Implementation}
    \begin{itemize}
        \item Function: \code{princomp()}
        \item Output: \code{summary()} for variance explained, \texttt{pc\_loadings} (or \code{pc\$loadings}) for eigenvectors, \code{screeplot()}, \code{biplot()}.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA Example: Investments}
    \begin{itemize}
        \item Reduce 8 investment categories to fewer components. First PC might capture difference between US stocks and alternative investments.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA Example: Kuiper Belt}
    \begin{itemize}
        \item Characterize Kuiper Belt objects (e.g., Pluto's reclassification) via lower-dimensional summaries.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA Example: Health Outcomes}
    \begin{itemize}
        \item Simplify multiple health metrics in hospitals to a few interpretable components.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{PCA: Takeaway}
    \begin{itemize}
        \item PCA finds simpler, interpretable dimensions in complex datasets, providing insights into underlying structures.
    \end{itemize}
\end{frame}

\section{Factor Analysis}

\begin{frame}
    \frametitle{Factor Analysis: Key idea}
    \begin{itemize}
        \item Factor Analysis explicitly posits \alert{latent variables} (factors) that cause the observed correlations among variables.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{FA vs PCA}
    \begin{itemize}
        \item PCA is a data transformation technique; Factor Analysis is a statistical model that explains observed variance using common factors and unique variances.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{FA: Concept}
    \begin{itemize}
        \item Each observed variable is a linear combination of one or more common factors (shared variance) and a unique factor (specific variance and error).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{FA: Goal}
    \begin{itemize}
        \item Goal: Identify these latent factors and quantify their influence on the observed variables.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Factor Rotation}
    \begin{itemize}
        \item A crucial step to improve interpretability of factor loadings. Rotations (e.g., Varimax, Promax) aim to achieve "simple structure" where each variable loads highly on only one factor and near zero on others.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{FA: R Implementation}
    \begin{itemize}
        \item Function: \code{factanal()}
        \item Requires specifying the number of factors.
        \item Example: Hamburger nutritional data (Calories, Fat, Sodium, etc.) might reveal factors like "Meat Content" and "Added Ingredients".
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{FA: Interpretation}
    \begin{itemize}
        \item Interpretation often involves a blend of statistical output and domain-specific knowledge.
    \end{itemize}
\end{frame}

\section{Confirmatory Factor Analysis (CFA)}

\begin{frame}
    \frametitle{Confirmatory Factor Analysis (CFA)}
    \framesubtitle{Supervised Approach and Model Specification}
    \begin{itemize}
        \item In contrast to PCA and exploratory Factor Analysis, CFA is a \alert{supervised} method.
        \item Allows researchers to \alert{test a pre-specified theory} or hypothesis about the factor structure.
        \item Instead of letting the data determine the factors, we hypothesize which variables load onto which latent factors based on prior knowledge.
    \item \textbf{Model Specification}: Defined using text syntax, where \texttt{latent\_variable =~ observed\_variable1 + observed\_variable2}. This indicates that the latent variable is measured by the specified observed variables.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Confirmatory Factor Analysis (CFA)}
    \framesubtitle{\R Implementation and Example}
    \begin{itemize}
        \item \textbf{\R Implementation}:
            \begin{itemize}
                \item Package: \code{lavaan}
                \item Function: \code{cfa()}
                \item Output includes factor loadings, standard errors, and fit measures ($\chi^2$ statistic, p-value).
            \end{itemize}
        \item \textbf{Example: Hamburger Data}
            \begin{itemize}
                \item Hypothesized latent variables: \code{meat} (measured by CalFat, Cal, Fat, SatFat, Protein) and \code{added} (measured by Sodium, Carbs).
                \item This allows incorporating nutritional knowledge directly into the model, leading to more meaningful interpretations.
            \end{itemize}
    \end{itemize}
\end{frame}

\section{Path Analysis}

\begin{frame}
    \frametitle{Path Analysis: Purpose}
    \begin{itemize}
        \item A multivariate statistical technique used to evaluate \alert{causal models} by examining the relationships between observed and latent variables.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Path Analysis: Directed relations}
    \begin{itemize}
        \item Focuses on directed relationships (causal paths) among variables.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Path Analysis: Latent variables}
    \begin{itemize}
        \item Can include both observed and \alert{latent variables} (which are themselves defined by observed indicators).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Path Diagrams}
    \begin{itemize}
        \item Model structure is visually represented by a \alert{path diagram}, showing arrows for directed effects and double-headed arrows for covariances.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Path Analysis: R tools}
    \begin{itemize}
        \item Package: \code{lavaan} (function \code{cfa()} or \code{sem()}). Visualization via \code{semPlot::semPaths()}.
        \item Model specification uses \texttt{=\~} for latent variables and \texttt{~} for regression relationships.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Path Example: Car data}
    \begin{itemize}
        \item Latent variables: \texttt{engine} (hp, cyl, disp, carb) and \texttt{drive\_train} (gear, drat, am).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Path Example: Predictions}
    \begin{itemize}
        \item These latent variables predict empirical measures like miles per gallon (\texttt{mpg}), weight (\texttt{wt}), and quarter-mile time (\texttt{qsec}).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Path Example: Visualisation}
    \begin{itemize}
        \item Path diagrams offer a clear way to convey complex structural relationships.
    \end{itemize}
\end{frame}

\section{SEM and LGM}

\begin{frame}
    \frametitle{SEM: Overview}
    \begin{itemize}
        \item SEM combines and extends factor analysis and path analysis.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{SEM: Measurement \& Structural}
    \begin{itemize}
        \item Simultaneously estimate measurement models (how latent variables are measured) and structural models (relationships between variables).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{SEM: Features}
    \begin{itemize}
        \item Can model complex relationships: indirect effects, mediation, moderation.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{SEM: R Implementation}
    \begin{itemize}
        \item \textbf{R Implementation}: \code{lavaan} package, using \code{sem()} function.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{LGM: Purpose}
    \begin{itemize}
        \item Latent Growth Models analyze longitudinal data by modeling individual trajectories (intercept and slope latent variables).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{LGM: Applications}
    \begin{itemize}
        \item Example: Modeling home price index trends across cities; latent slopes/intercepts can be influenced by demographics.
    \end{itemize}
\end{frame}

\section{Conclusion}

\begin{frame}
    \frametitle{Key Takeaway 1}
    \begin{itemize}
        \item Factor methods (PCA, Factor Analysis, CFA, Path Analysis, SEM/LGM) are essential tools for understanding complex multivariate data.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Key Takeaway 2}
    \begin{itemize}
        \item They help in \alert{data reduction}, uncovering \alert{latent structures}, and \alert{testing theoretical models}.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Key Takeaway 3}
    \begin{itemize}
        \item The choice of method depends on the research question and the extent of prior knowledge (exploratory vs. confirmatory).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Tools}
    \begin{itemize}
        \item \code{R} packages like \code{stats}, \code{MVA}, \code{lavaan}, and \code{semPlot} provide robust functionalities for implementing these methods.
    \end{itemize}
\end{frame}

\section*{References}
\begin{frame}
    \frametitle{References}
    \begin{itemize}
        \item Zelterman, D. (2022). \textit{Applied Multivariate Statistics with R} (Second ed.). Springer.
    \end{itemize}
\end{frame}

\end{document}
